{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras or Estimators?\n",
    "\n",
    "### What are Estimators? Put simply, they are another way to build or to use prebuilt bricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/toanmh/tensorflow_datasets/mnist/3.0.1...\u001b[0m\nWARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\nlocal data directory. If you'd instead prefer to read directly from our public\nGCS bucket (recommended if you're running on GCP), you can instead pass\n`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n\nDl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.65 file/s]\n\n\u001b[1mDataset mnist downloaded and prepared to /home/toanmh/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\ntest samples:  <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>\n\ntrain samples:  <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>\n"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds \n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "def input_fn(mode):\n",
    "    datasets, info = tfds.load(name='mnist',\n",
    "                            with_info=True,\n",
    "                            as_supervised=True)\n",
    "    \n",
    "    mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else datasets['test'])\n",
    "\n",
    "    def scale(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.\n",
    "\n",
    "        return image, label \n",
    "\n",
    "    return mnist_dataset.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "test = input_fn('test')\n",
    "train = input_fn(tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "print('test samples: ', test)\n",
    "print('\\ntrain samples: ', train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n",
    "    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitpy3tf2venv288287646c3141eb83ebaf47a044cd38",
   "display_name": "Python 3.6.9 64-bit ('py3_tf2': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
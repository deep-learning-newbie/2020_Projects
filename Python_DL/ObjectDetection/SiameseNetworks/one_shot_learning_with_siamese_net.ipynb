{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning with Siamese Networks using Keras-Tensorflow\n",
    "\n",
    "## What are Siamese Networks\n",
    "\n",
    "### Siamese networks are neural networks containing two or more identical subnetwork components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import cv2 \n",
    "import time \n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/media/toanmh/Workspace/Github/Datasets/omniglot-master/python/'\n",
    "train_folder = DATA_DIR + 'images_background/'\n",
    "val_folder = DATA_DIR + 'images_evaluation/'\n",
    "save_path = DATA_DIR + 'snapshots/'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_imgs(path, n=0):\n",
    "    X = []\n",
    "    y = []\n",
    "    cat_dict = {}\n",
    "    lang_dict = {}\n",
    "    curr_y = n\n",
    "    \n",
    "    for alphabet in os.listdir(path):\n",
    "        print('loading alphabet: ' + alphabet)\n",
    "        lang_dict[alphabet] = [curr_y, None]\n",
    "        alphabet_path = os.path.join(path, alphabet)\n",
    "        # every letter/category has it's own column in the array, so load seperately\n",
    "        for letter in os.listdir(alphabet_path):\n",
    "            cat_dict[curr_y] = (alphabet, letter)\n",
    "            category_images = []\n",
    "            letter_path = os.path.join(alphabet_path, letter)\n",
    "            # read all the images in the current category\n",
    "            for filename in os.listdir(letter_path):\n",
    "                image_path = os.path.join(letter_path, filename)\n",
    "                image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2GRAY)\n",
    "                category_images.append(image)\n",
    "                y.append(curr_y)\n",
    "            try:\n",
    "                X.append(np.stack(category_images))\n",
    "            except ValueError as e:\n",
    "                print('{} error - category_image {}'.format(e, category_images))\n",
    "\n",
    "            curr_y += 1\n",
    "            lang_dict[alphabet][1] = curr_y - 1\n",
    "    y = np.vstack(y)\n",
    "    X = np.stack(X)\n",
    "\n",
    "    return X, y, lang_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading alphabet: Alphabet_of_the_Magi\nloading alphabet: Anglo-Saxon_Futhorc\nloading alphabet: Arcadian\nloading alphabet: Armenian\nloading alphabet: Asomtavruli_(Georgian)\nloading alphabet: Balinese\nloading alphabet: Bengali\nloading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\nloading alphabet: Braille\nloading alphabet: Burmese_(Myanmar)\nloading alphabet: Cyrillic\nloading alphabet: Early_Aramaic\nloading alphabet: Futurama\nloading alphabet: Grantha\nloading alphabet: Greek\nloading alphabet: Gujarati\nloading alphabet: Hebrew\nloading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\nloading alphabet: Japanese_(hiragana)\nloading alphabet: Japanese_(katakana)\nloading alphabet: Korean\nloading alphabet: Latin\nloading alphabet: Malay_(Jawi_-_Arabic)\nloading alphabet: Mkhedruli_(Georgian)\nloading alphabet: N_Ko\nloading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\nloading alphabet: Sanskrit\nloading alphabet: Syriac_(Estrangelo)\nloading alphabet: Tagalog\nloading alphabet: Tifinagh\n"
    }
   ],
   "source": [
    "X, y, c = load_imgs(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the traing tensors on disk\n",
    "with open(os.path.join(save_path, 'train.pickle'), 'wb') as f:\n",
    "    pickle.dump((X, c), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading alphabet: Angelic\nloading alphabet: Atemayar_Qelisayer\nloading alphabet: Atlantean\nloading alphabet: Aurek-Besh\nloading alphabet: Avesta\nloading alphabet: Ge_ez\nloading alphabet: Glagolitic\nloading alphabet: Gurmukhi\nloading alphabet: Kannada\nloading alphabet: Keble\nloading alphabet: Malayalam\nloading alphabet: Manipuri\nloading alphabet: Mongolian\nloading alphabet: Old_Church_Slavonic_(Cyrillic)\nloading alphabet: Oriya\nloading alphabet: Sylheti\nloading alphabet: Syriac_(Serto)\nloading alphabet: Tengwar\nloading alphabet: Tibetan\nloading alphabet: ULOG\n"
    }
   ],
   "source": [
    "# loading the validation images into tensors\n",
    "Xval, yval, cval = load_imgs(val_folder)\n",
    "\n",
    "with open(os.path.join(save_path, 'val.pickle'), 'wb') as f:\n",
    "    pickle.dump((Xval, cval), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    values = np.random.normal(loc=0.0, scale=1e-2, size=shape)\n",
    "    return tf.keras.backend.variable(value=values, dtype=dtype)\n",
    "\n",
    "def initialize_bias(shape, dtype=None):\n",
    "    values = np.random.normal(loc=0.0, scale=1e-2, size=shape)\n",
    "    return tf.keras.backend.variable(value=values, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout, Lambda, Layer, Concatenate\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# create siamese model\n",
    "def get_siamese_model(input_shape):\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "\n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:tf.keras.backend.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    predict = Dense(1, activation='sigmoid', bias_initializer=initialize_bias)(L1_distance)\n",
    "\n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input, right_input], outputs=predict)\n",
    "\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_11 (InputLayer)           [(None, 105, 105, 1) 0                                            \n__________________________________________________________________________________________________\ninput_12 (InputLayer)           [(None, 105, 105, 1) 0                                            \n__________________________________________________________________________________________________\nsequential_5 (Sequential)       (None, 4096)         38947648    input_11[0][0]                   \n                                                                 input_12[0][0]                   \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 4096)         0           sequential_5[1][0]               \n                                                                 sequential_5[2][0]               \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            4097        lambda[0][0]                     \n==================================================================================================\nTotal params: 38,951,745\nTrainable params: 38,951,745\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = get_siamese_model((105, 105, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=6e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training alphabets: ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)', 'Balinese', 'Bengali', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Braille', 'Burmese_(Myanmar)', 'Cyrillic', 'Early_Aramaic', 'Futurama', 'Grantha', 'Greek', 'Gujarati', 'Hebrew', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Japanese_(hiragana)', 'Japanese_(katakana)', 'Korean', 'Latin', 'Malay_(Jawi_-_Arabic)', 'Mkhedruli_(Georgian)', 'N_Ko', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Sanskrit', 'Syriac_(Estrangelo)', 'Tagalog', 'Tifinagh']\n"
    }
   ],
   "source": [
    "# Loading the train tensors\n",
    "with open(os.path.join(save_path, 'train.pickle'), 'rb') as f:\n",
    "    (X_train, y_train) = pickle.load(f)\n",
    "\n",
    "print('Training alphabets: {}'.format(list(y_train.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'val.pickle'), 'rb') as f:\n",
    "    (X_val, y_val) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=batch_size, s='train'):\n",
    "    if s == 'train':\n",
    "        X, categories = X_train, y_train\n",
    "    else:\n",
    "        X, categories = X_val, y_val\n",
    "    n_classes, n_examples, w, h, c = X.shape\n",
    "\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "\n",
    "    pairs = [np.zeros((batch_size, h, w, 1)) for i in range(2)]\n",
    "\n",
    "    targets = np.zeros((batch_size, ))\n",
    "\n",
    "    targets[batch_size//2:] == 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, 1)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category\n",
    "        else:\n",
    "            category_2 = (category + np.random.randint(1, n_classes)) % n_classes\n",
    "\n",
    "        pairs[1][i, :, :, :] = X[category_2, idx_2].reshape(w, h, 1)\n",
    "\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(batch_size=batch_size, s='train'):\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, s)\n",
    "        yield(pairs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, s='val', language=None):\n",
    "    if s == 'train':\n",
    "        X, categories = X_train, y_train\n",
    "    else:\n",
    "        X, categories = X_val, y_val\n",
    "\n",
    "    n_classes, n_examples, w, h = X.shape \n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    if language is not None:\n",
    "        low, high = categories[language]\n",
    "        if N > high - low:\n",
    "            raise ValueError('This language ({}) has less than ({}) letters'.format(language, N))\n",
    "        categories = np.random.choice(range(low, high), size=(N, ), replace=False)\n",
    "\n",
    "    else:\n",
    "        categories = np.random.choice(range(n_classes), size=(N, ), replace=False)\n",
    "\n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choise(n_examples, size=(2,), replace=False)\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :]] * N).reshape(N, w, h, 1)\n",
    "    support_set = X[categories, indices,:,:]\n",
    "    support_set[0,:,:] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, 1)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "\n",
    "    return pairs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_oneshot(model, N, k, s='val', verbose=2):\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print('Evaluating model on {} rnaodm {} way one-shot learning tasks ...\\n'.format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, s)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "\n",
    "    precent_correct = (n_correct * 100.) / k \n",
    "    if verbose:\n",
    "        print('Got an average of {}% {} way one-shot learning accuracy \\n'.format(precent_correct, N))\n",
    "\n",
    "    return precent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "n_iter = 20000 # No. of training iterations\n",
    "N_way = 20 # how many classes for testing one-shot tasks\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 33075 into shape (105,105,1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-813506ed0fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-39a6f07e1071>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size, s)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0midx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0midx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 33075 into shape (105,105,1)"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "for i in range(1, n_iter):\n",
    "    (inputs, targets) = get_batch(batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(os.path.join(save_path, 'weights.{}.h5'.format(i))))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitpy3tf2venv91a9a20ebc5049b681447f9b261ae52b",
   "display_name": "Python 3.6.9 64-bit ('py3_tf2': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}